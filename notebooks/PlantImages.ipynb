{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, isdir, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__MACOSX\t\t\t\t     PlantCLEF2016Test\r\n",
      "PlantCLEF2015TestDataWithAnnotations\t     PlantCLEF2016Test.tar.gz\r\n",
      "PlantCLEF2015TestDataWithAnnotations.tar.gz  RunFilesToolAndResults\r\n",
      "PlantCLEF2015TrainingData\t\t     RunFilesToolAndResults.zip\r\n",
      "PlantCLEF2015TrainingData.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls /data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91758\n"
     ]
    }
   ],
   "source": [
    "train_path = \"/data/PlantCLEF2015TrainingData/train\"\n",
    "\n",
    "files = {\n",
    "    f.split(\".\")[0]: {\n",
    "        \"image\": join(train_path, f),\n",
    "        \"xml\": join(train_path, f.split(\".\")[0]+\".xml\")\n",
    "    } \n",
    "    for f in listdir(train_path)\n",
    "    if f[0] != \".\" and f[-3:] == \"jpg\"\n",
    "}\n",
    "\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91758/91758 [00:15<00:00, 5773.30it/s]\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "for f in tqdm(files):\n",
    "    xml = files[f]['xml']\n",
    "    tree = ET.parse(xml)\n",
    "    root = tree.getroot()\n",
    "    data = {}\n",
    "    for child in root:\n",
    "        data[child.tag] = child.text\n",
    "    files[f]['data'] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'Author': 'daniel barthelemy',\n",
      "          'ClassId': '4736',\n",
      "          'Content': 'Leaf',\n",
      "          'Date': '2013-11-3',\n",
      "          'Family': 'Rosaceae',\n",
      "          'Genus': 'Cydonia',\n",
      "          'ImageId2014': '36922',\n",
      "          'Latitude': '43.13079',\n",
      "          'LearnTag': 'Train',\n",
      "          'Location': 'Toulon',\n",
      "          'Longitude': '5.9022',\n",
      "          'MediaId': '9733',\n",
      "          'ObservationId': '13689',\n",
      "          'ObservationId2014': '7746',\n",
      "          'Species': 'Cydonia oblonga Mill.',\n",
      "          'Vote': '4',\n",
      "          'YearInCLEF': 'PlantCLEF2014'},\n",
      " 'image': '/data/PlantCLEF2015TrainingData/train/9733.jpg',\n",
      " 'xml': '/data/PlantCLEF2015TrainingData/train/9733.xml'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(files['9733'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"plant_clef_data.json\", \"w\") as F:\n",
    "    json.dump(files, F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data to TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_files = []\n",
    "labels    = []\n",
    "\n",
    "for f in files:\n",
    "    img_files.append(files[f]['image'])\n",
    "    labels.append(files[f]['data']['Content'])\n",
    "    \n",
    "IMG_WIDTH = 150\n",
    "IMG_HEIGHT = 150\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "Map = {}\n",
    "count = 0\n",
    "Labels = []\n",
    "\n",
    "for label in labels:\n",
    "    if not Map.get(label):\n",
    "        Map[label] = count\n",
    "        count += 1\n",
    "    Labels.append(Map[label])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.from_tensor_slices(img_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ds = list_ds.map(process_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ds = tf.data.Dataset.from_tensor_slices(Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
    "\n",
    "train_ds = train_ds.shuffle(1024).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 75, 75, 64)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 25, 25, 64)        16448     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 64)        16448     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2769152   \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 256)               0         \n",
      "=================================================================\n",
      "Total params: 2,802,880\n",
      "Trainable params: 2,802,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3)))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(\n",
    "    64, \n",
    "    (2,2), \n",
    "    strides=2,\n",
    "    activation='relu',\n",
    "    padding='same'\n",
    "))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(\n",
    "    64, \n",
    "    (2,2), \n",
    "    strides=3,\n",
    "    activation='relu',\n",
    "    padding='same'\n",
    "))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(\n",
    "    64, \n",
    "    (2,2), \n",
    "    strides=2,\n",
    "    activation='relu',\n",
    "    padding='same'\n",
    "))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(tf.keras.layers.Dense(256, activation=None))\n",
    "\n",
    "model.add(tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) # L2 normalize embeddings\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tfa.losses.TripletSemiHardLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "    503/Unknown - 181s 361ms/step - loss: 0.8997"
     ]
    }
   ],
   "source": [
    "# Train the network\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
