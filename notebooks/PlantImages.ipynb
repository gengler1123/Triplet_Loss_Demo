{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, isdir, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91758\n"
     ]
    }
   ],
   "source": [
    "train_path = \"/data/Plant_Clef/train\"\n",
    "\n",
    "files = {\n",
    "    f.split(\".\")[0]: {\n",
    "        \"image\": join(train_path, f),\n",
    "        \"xml\": join(train_path, f.split(\".\")[0]+\".xml\")\n",
    "    } \n",
    "    for f in listdir(train_path)\n",
    "    if f[0] != \".\" and f[-3:] == \"jpg\"\n",
    "}\n",
    "\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91758/91758 [07:32<00:00, 202.91it/s]\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "for f in tqdm(files):\n",
    "    xml = files[f]['xml']\n",
    "    tree = ET.parse(xml)\n",
    "    root = tree.getroot()\n",
    "    data = {}\n",
    "    for child in root:\n",
    "        data[child.tag] = child.text\n",
    "    files[f]['data'] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'Author': 'daniel barthelemy',\n",
      "          'ClassId': '4736',\n",
      "          'Content': 'Leaf',\n",
      "          'Date': '2013-11-3',\n",
      "          'Family': 'Rosaceae',\n",
      "          'Genus': 'Cydonia',\n",
      "          'ImageId2014': '36922',\n",
      "          'Latitude': '43.13079',\n",
      "          'LearnTag': 'Train',\n",
      "          'Location': 'Toulon',\n",
      "          'Longitude': '5.9022',\n",
      "          'MediaId': '9733',\n",
      "          'ObservationId': '13689',\n",
      "          'ObservationId2014': '7746',\n",
      "          'Species': 'Cydonia oblonga Mill.',\n",
      "          'Vote': '4',\n",
      "          'YearInCLEF': 'PlantCLEF2014'},\n",
      " 'image': '/data/Plant_Clef/train/9733.jpg',\n",
      " 'xml': '/data/Plant_Clef/train/9733.xml'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(files['9733'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"plant_clef_data.json\", \"w\") as F:\n",
    "    json.dump(files, F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data to TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_files = []\n",
    "labels    = []\n",
    "\n",
    "for f in files:\n",
    "    img_files.append(files[f]['image'])\n",
    "    labels.append(files[f]['data']['Content'])\n",
    "    \n",
    "IMG_WIDTH = 150\n",
    "IMG_HEIGHT = 150\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "Map = {}\n",
    "count = 0\n",
    "Labels = []\n",
    "\n",
    "for label in labels:\n",
    "    if not Map.get(label):\n",
    "        Map[label] = count\n",
    "        count += 1\n",
    "    Labels.append(Map[label])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.from_tensor_slices(img_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ds = list_ds.map(process_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ds = tf.data.Dataset.from_tensor_slices(Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
    "\n",
    "train_ds = train_ds.shuffle(1024).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 75, 75, 64)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 25, 25, 64)        16448     \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 13, 13, 64)        16448     \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               2769152   \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 256)               0         \n",
      "=================================================================\n",
      "Total params: 2,802,880\n",
      "Trainable params: 2,802,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3)))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(\n",
    "    64, \n",
    "    (2,2), \n",
    "    strides=2,\n",
    "    activation='relu',\n",
    "    padding='same'\n",
    "))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(\n",
    "    64, \n",
    "    (2,2), \n",
    "    strides=3,\n",
    "    activation='relu',\n",
    "    padding='same'\n",
    "))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(\n",
    "    64, \n",
    "    (2,2), \n",
    "    strides=2,\n",
    "    activation='relu',\n",
    "    padding='same'\n",
    "))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(tf.keras.layers.Dense(256, activation=None))\n",
    "\n",
    "model.add(tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) # L2 normalize embeddings\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tfa.losses.TripletSemiHardLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "    184/Unknown - 2818s 15s/step - loss: 0.9088"
     ]
    }
   ],
   "source": [
    "# Train the network\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
